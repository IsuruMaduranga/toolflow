"""
Live Integration Tests for Toolflow with Anthropic

These tests use actual Anthropic API calls to verify end-to-end functionality.
Set ANTHROPIC_API_KEY environment variable to run these tests.

Run with: python -m pytest tests/anthropic/test_integration_live.py -v -s

Note: These tests make real API calls and will consume Anthropic credits.
"""

import os
import asyncio
import time
from typing import List, Optional, Dict, Any
import pytest
from dotenv import load_dotenv
load_dotenv()

try:
    import pytest_asyncio
    PYTEST_ASYNCIO_AVAILABLE = True
except ImportError:
    PYTEST_ASYNCIO_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from pydantic import BaseModel, Field
    PYDANTIC_AVAILABLE = True
except ImportError:
    PYDANTIC_AVAILABLE = False
    BaseModel = None

import toolflow


# Skip all tests if Anthropic API key is not available
pytestmark = pytest.mark.skipif(
    not os.getenv("ANTHROPIC_API_KEY") or not ANTHROPIC_AVAILABLE,
    reason="Anthropic API key not available or anthropic package not installed"
)


# Test Models for structured output support
@pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
class WeatherInfo(BaseModel):
    city: str
    temperature: int
    condition: str
    humidity: Optional[int] = None


@pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
class MathResult(BaseModel):
    operation: str
    operands: List[float]
    result: float
    explanation: str


@pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
class BookRecommendation(BaseModel):
    title: str
    author: str
    genre: str
    year_published: int
    reason: str


@pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
class WeatherData(BaseModel):
    city: str
    temperature: float
    condition: str
    humidity: int


# Test Tools
@toolflow.tool
def simple_calculator(operation: str, a: float, b: float) -> float:
    """Perform basic mathematical operations: add, subtract, multiply, divide."""
    if operation == "add":
        return a + b
    elif operation == "subtract":
        return a - b
    elif operation == "multiply":
        return a * b
    elif operation == "divide":
        if b == 0:
            raise ValueError("Cannot divide by zero")
        return a / b
    else:
        raise ValueError(f"Unknown operation: {operation}")


@toolflow.tool
def get_fibonacci(n: int) -> int:
    """Calculate the nth Fibonacci number."""
    if n <= 1:
        return n
    if n > 20:  # Limit for performance
        return -1
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b


@toolflow.tool
def get_system_info(info_type: str) -> str:
    """Get system information. Available types: time, version, status."""
    if info_type == "time":
        return f"Current time: {time.strftime('%Y-%m-%d %H:%M:%S')}"
    elif info_type == "version":
        return "Toolflow Version 1.0.0"
    elif info_type == "status":
        return "System Status: All systems operational"
    else:
        return f"Unknown info type: {info_type}"


@toolflow.tool
async def async_delay_calculator(seconds: float, value: float) -> float:
    """Perform calculation after a delay (async tool)."""
    await asyncio.sleep(min(seconds, 2.0))  # Cap at 2 seconds for tests
    return value * 2


@toolflow.tool
def format_data(data: str, format_type: str = "uppercase") -> str:
    """Format data according to specified type: uppercase, lowercase, title."""
    if format_type == "uppercase":
        return data.upper()
    elif format_type == "lowercase":
        return data.lower()
    elif format_type == "title":
        return data.title()
    else:
        return data


@toolflow.tool
def get_weather(location: str) -> str:
    """Get weather for a given location (mock implementation)."""
    return f"Weather in {location}: Sunny, 72Â°F with light winds"


@toolflow.tool
def calculate_advanced(expression: str) -> str:
    """Calculate a mathematical expression and explain the result."""
    try:
        # Simple evaluation for demo purposes
        result = eval(expression)
        return f"The result of {expression} is {result}. This was calculated using standard arithmetic operations."
    except Exception as e:
        return f"Error calculating {expression}: {str(e)}"


@toolflow.tool
async def search_books(genre: str, year_range: str = "recent") -> str:
    """Search for book recommendations in a specific genre."""
    # Simulate book search API
    books = {
        "science fiction": "Klara and the Sun by Kazuo Ishiguro (2021) - A beautiful exploration of AI consciousness",
        "mystery": "The Thursday Murder Club by Richard Osman (2020) - A cozy mystery with elderly detectives",
        "fantasy": "The Priory of the Orange Tree by Samantha Shannon (2019) - Epic fantasy with dragons"
    }
    return books.get(genre.lower(), f"No recent recommendations found for {genre}")


class TestBasicAnthropicToolCalling:
    """Test basic tool calling functionality with real Anthropic API."""

    @pytest.fixture
    def client(self):
        """Create toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    def test_single_tool_call(self, client):
        """Test calling a single tool."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "What is 15 + 27?"}],
            tools=[simple_calculator],
            max_tool_calls=3
        )
        
        assert response is not None
        assert "42" in response

    def test_multiple_tool_calls(self, client):
        """Test calling multiple tools in sequence."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate 10 + 5, then multiply the result by 3"}],
            tools=[simple_calculator],
            max_tool_calls=5
        )
        
        assert response is not None
        assert "45" in response

    def test_parallel_tool_execution(self, client):
        """Test parallel tool execution performance."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate the 10th and 12th Fibonacci numbers"}],
            tools=[get_fibonacci],
            parallel_tool_execution=True,
            max_tool_calls=5
        )
        
        assert response is not None
        # Should mention both Fibonacci numbers
        content = response
        assert any(str(num) in content for num in [55, 144])  # 10th=55, 12th=144

    def test_mixed_tool_types(self, client):
        """Test using different types of tools together."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Add 10 and 20, get current time, and format 'hello world' in uppercase"}],
            tools=[simple_calculator, get_system_info, format_data],
            max_tool_calls=5
        )
        
        assert response is not None
        content = response
        assert "30" in content  # Addition result
        assert "HELLO WORLD" in content  # Formatted text

    def test_system_message(self, client):
        """Test using system messages with Anthropic."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            system="You are a helpful math assistant. Always use the calculator tool for calculations.",
            messages=[{"role": "user", "content": "What is 25 * 4?"}],
            tools=[simple_calculator],
            max_tool_calls=3
        )
        
        assert response is not None
        assert "100" in response

    def test_weather_tool_with_system(self, client):
        """Test weather tool with system context."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            system="You are a travel assistant. Use the weather tool to help users plan their trips.",
            messages=[{"role": "user", "content": "What's the weather like in San Francisco?"}],
            tools=[get_weather],
            max_tool_calls=3
        )
        
        assert response is not None
        assert "San Francisco" in response
        assert "weather" in response.lower()


class TestAnthropicAsyncFunctionality:
    """Test async functionality with Anthropic."""

    @pytest.fixture
    def async_client(self):
        """Create async toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_async_client_sync_tools(self, async_client):
        """Test async client with sync tools."""
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "What is 20 * 3?"}],
            tools=[simple_calculator],
            max_tool_calls=3
        )
        
        assert response is not None
        assert "60" in response

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_async_client_async_tools(self, async_client):
        """Test async client with async tools."""
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate 5 * 2 with a small delay"}],
            tools=[async_delay_calculator],
            max_tool_calls=3
        )
        
        assert response is not None
        assert "10" in response  # 5 * 2 = 10

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_async_client_mixed_tools(self, async_client):
        """Test async client with both sync and async tools."""
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Add 15 and 25, then double the result with a delay"}],
            tools=[simple_calculator, async_delay_calculator],
            parallel_tool_execution=True,
            max_tool_calls=5
        )
        
        assert response is not None
        # Result should be (15 + 25) * 2 = 80
        assert "80" in response

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_async_parallel_tool_execution(self, async_client):
        """Test async parallel tool execution."""
        start_time = time.time()
        
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate Fibonacci numbers for 8, 9, and 10, and get the current time"}],
            tools=[get_fibonacci, get_system_info],
            parallel_tool_execution=True,
            max_tool_calls=8
        )
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        assert response is not None
        # Should contain multiple Fibonacci results and time info
        assert "21" in response  # Fib(8)
        assert "34" in response  # Fib(9)
        assert "55" in response  # Fib(10)
        assert "time" in response.lower()
        
        # Parallel execution should be reasonably fast
        assert execution_time < 30  # Should complete within 30 seconds


class TestAnthropicStreamingFunctionality:
    """Test streaming functionality with Anthropic."""

    @pytest.fixture
    def client(self):
        """Create toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    def test_streaming_with_tools(self, client):
        """Test streaming with tool execution."""
        stream = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "What is 7 * 6?"}],
            tools=[simple_calculator],
            stream=True,
            max_tool_calls=3
        )
        
        content_chunks = []
        for chunk in stream:
            if chunk:
                content_chunks.append(chunk)
        
        full_content = "".join(content_chunks)
        assert "42" in full_content

    def test_streaming_without_tools(self, client):
        """Test streaming without tools."""
        stream = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Write a short poem about AI"}],
            stream=True
        )
        
        content_chunks = []
        for chunk in stream:
            if chunk:
                content_chunks.append(chunk)
        
        full_content = "".join(content_chunks)
        assert len(full_content) > 50  # Should be a reasonable poem
        assert any(word in full_content.lower() for word in ["ai", "artificial", "intelligence", "computer"])

    def test_streaming_with_parallel_tools(self, client):
        """Test streaming with parallel tool execution."""
        stream = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate 8 * 9, get the current time, and format 'testing' in uppercase"}],
            tools=[simple_calculator, get_system_info, format_data],
            stream=True,
            parallel_tool_execution=True,
            max_tool_calls=6
        )
        
        content_chunks = []
        for chunk in stream:
            if chunk:
                content_chunks.append(chunk)
        
        full_content = "".join(content_chunks)
        assert "72" in full_content  # 8 * 9
        assert "TESTING" in full_content  # Formatted text
        assert any(word in full_content.lower() for word in ["time", "current"])

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available") 
    @pytest.mark.asyncio
    async def test_async_streaming_with_tools(self):
        """Test async streaming with tools."""
        async_client = toolflow.from_anthropic(
            anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        )
        
        stream = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "What is 9 * 4?"}],
            tools=[simple_calculator],
            stream=True,
            max_tool_calls=3
        )
        
        content_chunks = []
        async for chunk in stream:
            if chunk:
                content_chunks.append(chunk)
        
        full_content = "".join(content_chunks)
        assert "36" in full_content

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_async_streaming_without_tools(self):
        """Test async streaming without tools."""
        async_client = toolflow.from_anthropic(
            anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        )
        
        stream = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Count from 1 to 5"}],
            stream=True
        )
        
        content_chunks = []
        async for chunk in stream:
            if chunk:
                content_chunks.append(chunk)
        
        full_content = "".join(content_chunks)
        assert len(full_content) > 10
        # Should contain numbers
        assert any(str(num) in full_content for num in [1, 2, 3, 4, 5])

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_async_streaming_with_parallel_tools(self):
        """Test async streaming with parallel tool execution."""
        async_client = toolflow.from_anthropic(
            anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        )
        
        stream = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate Fibonacci of 7, multiply 6 by 8, and get system status"}],
            tools=[get_fibonacci, simple_calculator, get_system_info],
            stream=True,
            parallel_tool_execution=True,
            max_tool_calls=6
        )
        
        content_chunks = []
        async for chunk in stream:
            if chunk:
                content_chunks.append(chunk)
        
        full_content = "".join(content_chunks)
        assert "13" in full_content  # Fib(7)
        assert "48" in full_content  # 6 * 8
        assert "operational" in full_content.lower() or "status" in full_content.lower()


class TestAnthropicErrorHandling:
    """Test error handling with Anthropic."""

    @pytest.fixture
    def client(self):
        """Create toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    def test_tool_execution_error(self, client):
        """Test handling of tool execution errors."""
        @toolflow.tool
        def divide_by_zero(x: float) -> float:
            """Divide by zero (will cause error)."""
            return x / 0
        
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Please divide 10 by zero"}],
            tools=[divide_by_zero],
            graceful_error_handling=True,
            max_tool_calls=3
        )
        
        assert response is not None
        # Should handle the error gracefully
        assert any(word in response.lower() for word in ["error", "divide", "zero"])

    def test_max_tool_calls_limit(self, client):
        """Test that max tool calls limit is respected."""
        call_count = 0
        
        @toolflow.tool
        def recursive_tool(task: str) -> str:
            """A tool that always requests another call."""
            nonlocal call_count
            call_count += 1
            if call_count < 5:  # Ensure it keeps requesting more calls
                return f"Call {call_count}: {task}. Please call me again with task 'continue'"
            return f"Final call {call_count}: {task}"
        
        with pytest.raises(Exception, match="Max tool calls reached"):
            client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=1024,
                messages=[{"role": "user", "content": "Call the recursive_tool with task 'start' and keep calling it until it's done. The tool will tell you when to call it again."}],
                tools=[recursive_tool],
                max_tool_calls=2  # Low limit
            )


class TestAnthropicStructuredOutput:
    """Test Anthropic structured output functionality."""
    
    @pytest.fixture
    def client(self):
        """Create toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    def test_structured_output_weather(self, client):
        """Test structured output with weather tool."""
        result = client.messages.create(
            model="claude-3-sonnet-20240229",
            messages=[{
                "role": "user", 
                "content": "Get the weather for New York and format it as structured data"
            }],
            tools=[get_weather],
            response_format=WeatherData,
            max_tokens=1000
        )
        
        # Should return parsed Pydantic model
        assert isinstance(result, WeatherData)
        assert result.city == "New York"
        assert isinstance(result.temperature, float)
        assert isinstance(result.condition, str)
        assert isinstance(result.humidity, int)

    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    def test_structured_output_math(self, client):
        """Test structured output with math calculation."""
        result = client.messages.create(
            model="claude-3-sonnet-20240229",
            messages=[{
                "role": "user", 
                "content": "Calculate 15 * 8 + 7 and provide a structured result with explanation"
            }],
            tools=[calculate_advanced],
            response_format=MathResult,
            max_tokens=1000
        )
        
        # Should return parsed Pydantic model
        assert isinstance(result, MathResult)
        assert isinstance(result.operation, str)
        assert isinstance(result.operands, list)
        assert result.result == 127.0  # 15 * 8 + 7 = 127
        assert isinstance(result.explanation, str)
        assert len(result.explanation) > 10

    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    def test_structured_output_without_tools(self, client):
        """Test structured output without any tools."""
        result = client.messages.create(
            model="claude-3-sonnet-20240229",
            messages=[{
                "role": "user", 
                "content": "Recommend a good science fiction book published in the last 5 years"
            }],
            response_format=BookRecommendation,
            max_tokens=1000
        )
        
        # Should return parsed Pydantic model
        assert isinstance(result, BookRecommendation)
        assert isinstance(result.title, str)
        assert isinstance(result.author, str)
        assert result.genre.lower() == "science fiction"
        assert isinstance(result.year_published, int)
        # Be more flexible with year - AI models may not always follow the exact constraint
        assert result.year_published >= 2010  # Still relatively recent
        assert isinstance(result.reason, str)
        assert len(result.reason) > 20

    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    def test_structured_output_full_response_mode(self, client):
        """Test structured output in full response mode."""
        client_full = toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")), full_response=True)
        
        result = client_full.messages.create(
            model="claude-3-sonnet-20240229",
            messages=[{
                "role": "user", 
                "content": "Get weather for London and structure the response"
            }],
            tools=[get_weather],
            response_format=WeatherData,
            max_tokens=1000
        )
        
        # With full_response=True, toolflow should add a parsed attribute to the response
        # But if not available, just verify we get a proper response object
        if hasattr(result, 'parsed'):
            parsed = result.parsed
            assert isinstance(parsed, WeatherData)
            assert parsed.city == "London"
            assert isinstance(parsed.temperature, float)
            assert isinstance(parsed.condition, str)
            assert isinstance(parsed.humidity, int)
        else:
            # Fallback: verify we get a proper response object
            assert hasattr(result, 'content')
            assert len(result.content) > 0
            # The structured response should be embedded in the response content
            assert result.content is not None

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    @pytest.mark.asyncio
    async def test_async_structured_output(self):
        """Test async structured output functionality."""
        client = toolflow.from_anthropic(anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))
        
        result = await client.messages.create(
            model="claude-3-sonnet-20240229",
            messages=[{
                "role": "user", 
                "content": "Search for a good mystery book and provide structured information"
            }],
            tools=[search_books],
            response_format=BookRecommendation,
            max_tokens=1000
        )
        
        # Should return parsed Pydantic model
        assert isinstance(result, BookRecommendation)
        assert isinstance(result.title, str)
        assert isinstance(result.author, str)
        assert result.genre.lower() == "mystery"
        assert isinstance(result.year_published, int)
        assert isinstance(result.reason, str)

    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    def test_structured_output_error_handling(self, client):
        """Test structured output error handling with invalid response format."""
        # Test with invalid response format
        with pytest.raises(ValueError, match="Response format .* is not a Pydantic model"):
            client.messages.create(
                model="claude-3-sonnet-20240229",
                messages=[{"role": "user", "content": "Hello"}],
                response_format=dict,  # Invalid - not a Pydantic model
                max_tokens=1000
            )

    @pytest.mark.skipif(not PYDANTIC_AVAILABLE, reason="Pydantic not available")
    def test_structured_output_streaming_error(self, client):
        """Test that structured output with streaming raises an error."""
        # Test streaming with response_format should raise error
        with pytest.raises(ValueError, match="response_format is not supported for streaming"):
            client.messages.create(
                model="claude-3-sonnet-20240229",
                messages=[{"role": "user", "content": "Hello"}],
                response_format=WeatherData,
                stream=True,
                max_tokens=1000
            )


class TestAnthropicComprehensiveWorkflow:
    """Test comprehensive workflows with Anthropic."""

    @pytest.fixture
    def client(self):
        """Create toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    def test_full_workflow_sync(self, client):
        """Test a complete workflow with multiple tool types."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            system="You are a helpful assistant that uses tools to solve problems step by step.",
            messages=[{
                "role": "user", 
                "content": "Calculate 15 + 25, get the current time, format 'HELLO world' to title case, and tell me the weather in Tokyo"
            }],
            tools=[simple_calculator, get_system_info, format_data, get_weather],
            parallel_tool_execution=True,
            max_tool_calls=10
        )
        
        assert response is not None
        content = response.lower()
        
        # Check all expected results
        assert "40" in response  # 15 + 25
        assert "hello world" in content  # Title case formatting
        assert "tokyo" in content  # Weather info
        assert any(word in content for word in ["time", "current"])  # Time info

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_full_workflow_async(self):
        """Test a complete async workflow."""
        async_client = toolflow.from_anthropic(
            anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        )
        
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            system="You are an async assistant that efficiently handles multiple tasks.",
            messages=[{
                "role": "user",
                "content": "Multiply 6 by 7, then calculate the Fibonacci of 8, and get system status"
            }],
            tools=[simple_calculator, get_fibonacci, get_system_info],
            parallel_tool_execution=True,
            max_tool_calls=8
        )
        
        assert response is not None
        content = response.lower()
        
        # Check expected results
        assert "42" in response  # 6 * 7
        assert "21" in response  # Fibonacci(8)
        assert "operational" in content  # System status

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.asyncio
    async def test_full_workflow_async_with_mixed_tools(self):
        """Test full async workflow with mixed sync/async tools."""
        async_client = toolflow.from_anthropic(
            anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        )
        
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            system="You are an efficient assistant that uses tools to solve complex tasks.",
            messages=[{
                "role": "user",
                "content": "Calculate 18 / 3, double the result with a delay, and get weather for London"
            }],
            tools=[simple_calculator, async_delay_calculator, get_weather],
            parallel_tool_execution=True,
            max_tool_calls=8
        )
        
        assert response is not None
        content = response.lower()
        
        # Check expected results: 18/3 = 6, then 6*2 = 12
        assert "6" in response or "12" in response  # Either step result
        assert "london" in content  # Weather info


class TestAnthropicPerformanceBenchmarks:
    """Test performance characteristics of Anthropic integration."""

    @pytest.fixture
    def client(self):
        """Create toolflow wrapped Anthropic client."""
        return toolflow.from_anthropic(anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")))

    @pytest.mark.skipif(True, reason="Performance test - run manually if needed")
    def test_parallel_vs_sequential_performance(self, client):
        """Compare parallel vs sequential tool execution performance."""
        
        # Sequential execution
        start_time = time.time()
        response_seq = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate Fibonacci for 10, 11, 12, and 13"}],
            tools=[get_fibonacci],
            parallel_tool_execution=False,
            max_tool_calls=10
        )
        sequential_time = time.time() - start_time
        
        # Parallel execution
        start_time = time.time()
        response_par = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate Fibonacci for 10, 11, 12, and 13"}],
            tools=[get_fibonacci],
            parallel_tool_execution=True,
            max_tool_calls=10
        )
        parallel_time = time.time() - start_time
        
        # Both should get correct results
        assert "55" in response_seq  # Fib(10)
        assert "89" in response_seq  # Fib(11)
        assert "55" in response_par  # Fib(10)
        assert "89" in response_par  # Fib(11)
        
        print(f"Sequential time: {sequential_time:.2f}s")
        print(f"Parallel time: {parallel_time:.2f}s")
        if parallel_time > 0:
            print(f"Speedup: {sequential_time / parallel_time:.2f}x")

    @pytest.mark.skipif(True, reason="Large scale test - run manually if needed")
    def test_large_parallel_execution(self, client):
        """Test large scale parallel execution."""
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate fibonacci numbers from 5 to 15"}],
            tools=[get_fibonacci],
            parallel_tool_execution=True,
            max_tool_calls=12,
            max_workers=5
        )
        
        assert response is not None
        content = response
        
        # Should contain multiple Fibonacci numbers
        fibonacci_sequence = [5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]
        found_numbers = sum(1 for num in fibonacci_sequence if str(num) in content)
        assert found_numbers >= 5  # Should find at least 5 of the expected numbers

    @pytest.mark.skipif(not PYTEST_ASYNCIO_AVAILABLE, reason="pytest-asyncio not available")
    @pytest.mark.skipif(True, reason="Performance test - run manually if needed")
    @pytest.mark.asyncio
    async def test_async_parallel_performance(self):
        """Test async parallel execution performance."""
        async_client = toolflow.from_anthropic(
            anthropic.AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        )
        
        start_time = time.time()
        
        response = await async_client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Calculate multiple operations: 12*8, 15+25, 100/4, get time, and format 'async' in title case"}],
            tools=[simple_calculator, get_system_info, format_data],
            parallel_tool_execution=True,
            max_tool_calls=10
        )
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        assert response is not None
        content = response
        
        # Check for expected results
        assert "96" in content  # 12*8
        assert "40" in content  # 15+25
        assert "25" in content  # 100/4
        assert "Async" in content  # Formatted text
        
        print(f"Async parallel execution time: {execution_time:.2f}s")
        assert execution_time < 30  # Should complete reasonably fast


if __name__ == "__main__":
    # Run a quick test to verify setup
    if not os.getenv("ANTHROPIC_API_KEY"):
        print("â ANTHROPIC_API_KEY environment variable not set")
        print("Set it with: export ANTHROPIC_API_KEY='your-api-key'")
        exit(1)
    
    if not ANTHROPIC_AVAILABLE:
        print("â Anthropic package not available")
        print("Install it with: pip install anthropic")
        exit(1)
    
    print("â Environment setup complete")
    print("Run tests with: python -m pytest tests/anthropic/test_integration_live.py -v -s")
    print("Note: These tests will consume Anthropic API credits") 